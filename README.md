# Experiments-with-Deep-Learning-Models
There are many convolutional neural network architectures developed for various tasks such as classification and detection of images. In this project, 3 of such architectures are studied and implemented - VGGNet16, ResNet18 and Inception V2. Along with implementations of these architectures, various combinations of regularization techniques and optimizers are experimented. The regularization techniques used are - Batch Normalization and Dropout while optimizers include ADAM and SGD. The observations from these 18 experiments can help us analyse which optimizer works best with which regularization technique. Also, we will be able to identify how regularization helps in achieving higher accuracies than models with no regularization. These observations are discussed in detail in the results section of the report.
