{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "InceptionV2_adam_NoRegularization.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qe3UvwFPYKMT"
      },
      "source": [
        "## Load Data Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Su96RREPI5li",
        "outputId": "1656be09-05eb-46ba-dc04-968531b92301",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ixBthpNWrKzY"
      },
      "source": [
        "from keras.datasets import cifar100\n",
        "from keras.utils import to_categorical\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "from keras import backend as K"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d14LEXbNqu68",
        "outputId": "9aeb1122-38fe-40fd-8565-b9da1b40f842",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "(x_train, y_train_), (x_test, y_test_) = cifar100.load_data()\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
            "169009152/169001437 [==============================] - 6s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p4lTzEl8djyJ"
      },
      "source": [
        "x_train = x_train.astype('float32') / 255\n",
        "x_test = x_test.astype('float32') / 255"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6h_PwVSJrWjf"
      },
      "source": [
        "y_train = to_categorical(y_train_)\n",
        "y_test = to_categorical(y_test_)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fsSOLpMSYEKL"
      },
      "source": [
        "## Inception V2 model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DlX5MwqCoSEF"
      },
      "source": [
        "import keras\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense, Activation, Dropout, Flatten, Reshape\n",
        "from keras.layers import Conv2D, Input\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.layers.merge import concatenate\n",
        "import os"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RfDkIclipUCR"
      },
      "source": [
        "input_shape = (32, 32, 3)\n",
        "input = Input(shape=input_shape)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t1Cv1ygQ7Cwj"
      },
      "source": [
        "layer1_1 = Conv2D(64, (1, 1), activation='elu', padding='same')(input)\n",
        "layer1_2 = Conv2D(96, (1, 1), activation='elu', padding='same')(input)\n",
        "layer1_2 = Conv2D(128, (3, 3), activation='elu', padding='same')(layer1_2)\n",
        "layer1_3 = Conv2D(16, (1, 1), activation='elu', padding='same')(input)\n",
        "layer1_3 = Conv2D(32, (5, 5), activation='elu', padding='same')(layer1_3)\n",
        "layer1_4 = MaxPooling2D(pool_size=(3, 3), strides=(1, 1), padding='same', data_format='channels_last')(input)\n",
        "layer1_4 = Conv2D(32, (1, 1), activation='elu', padding='same')(layer1_4)\n",
        " \n",
        "concat = concatenate([layer1_1, layer1_2, layer1_3, layer1_4])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZgqX4ij5wn7J"
      },
      "source": [
        "layer2_1 = Conv2D(64, (1, 1), activation='elu', padding='same')(concat)\n",
        "layer2_2 = Conv2D(96, (1, 1), activation='elu', padding='same')(concat)\n",
        "layer2_2 = Conv2D(128, (3, 3), activation='elu', padding='same')(layer2_2)\n",
        "layer2_3 = Conv2D(16, (1, 1), activation='elu', padding='same')(concat)\n",
        "layer2_3 = Conv2D(32, (5, 5), activation='elu', padding='same')(layer2_3)\n",
        "layer2_4 = MaxPooling2D(pool_size=(3, 3), strides=(1, 1), padding='same', data_format='channels_last')(concat)\n",
        "layer2_4 = Conv2D(32, (1, 1), activation='elu', padding='same')(layer2_4)\n",
        "\n",
        "concat2 = concatenate([layer2_1, layer2_2, layer2_3, layer2_4])"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4RzN660c7naC"
      },
      "source": [
        "layer3_1 = Conv2D(64, (1, 1), activation='elu', padding='same')(concat2)\n",
        "layer3_2 = Conv2D(96, (1, 1), activation='elu', padding='same')(concat2)\n",
        "layer3_2 = Conv2D(128, (3, 3), activation='elu', padding='same')(layer3_2)\n",
        "layer3_3 = Conv2D(16, (1, 1), activation='elu', padding='same')(concat2)\n",
        "layer3_3 = Conv2D(32, (5, 5), activation='elu', padding='same')(layer3_3)\n",
        "layer3_4 = MaxPooling2D(pool_size=(3, 3), strides=(1, 1), padding='same', data_format='channels_last')(concat2)\n",
        "layer3_4 = Conv2D(32, (1, 1), activation='elu', padding='same')(layer3_4)\n",
        " \n",
        "concat3 = concatenate([layer3_1, layer3_2, layer3_3, layer3_4])"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BqQohLdvpaGV",
        "outputId": "13dedcd1-9983-4844-9b85-e2bc3875bd93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "layer4_1 = Conv2D(64, (1, 1), activation='elu', padding='same')(concat3)\n",
        "layer4_2 = Conv2D(96, (1, 1), activation='elu', padding='same')(concat3)\n",
        "layer4_2 = Conv2D(128, (3, 3), activation='elu', padding='same')(layer4_2)\n",
        "layer4_3 = Conv2D(16, (1, 1), activation='elu', padding='same')(concat3)\n",
        "layer4_3 = Conv2D(32, (5, 5), activation='elu', padding='same')(layer4_3)\n",
        "layer4_4 = MaxPooling2D(pool_size=(3, 3), strides=(1, 1), padding='same', data_format='channels_last')(concat3)\n",
        "layer4_4 = Conv2D(32, (1, 1), activation='elu', padding='same')(layer4_4)\n",
        " \n",
        "concat4 = concatenate([layer4_1, layer4_2, layer4_3, layer4_4])\n",
        "\n",
        "output = Conv2D(8, (3, 3), activation='elu', padding='same')(concat4)\n",
        "output = MaxPooling2D(pool_size=(3, 3))(output)\n",
        "output = Flatten()(output)                 \n",
        "output = Dense(100, activation='softmax')(output) \n",
        "\n",
        "model = Model(inputs=input, outputs=output) \n",
        "model.summary()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 32, 32, 96)   384         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 32, 32, 16)   64          input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 32, 32, 3)    0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 32, 32, 64)   256         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 32, 32, 128)  110720      conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 32, 32, 32)   12832       conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 32, 32, 32)   128         max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 32, 32, 256)  0           conv2d[0][0]                     \n",
            "                                                                 conv2d_2[0][0]                   \n",
            "                                                                 conv2d_4[0][0]                   \n",
            "                                                                 conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 32, 32, 96)   24672       concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 32, 32, 16)   4112        concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 32, 32, 256)  0           concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 32, 32, 64)   16448       concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 32, 32, 128)  110720      conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 32, 32, 32)   12832       conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 32, 32, 32)   8224        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 32, 32, 256)  0           conv2d_6[0][0]                   \n",
            "                                                                 conv2d_8[0][0]                   \n",
            "                                                                 conv2d_10[0][0]                  \n",
            "                                                                 conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 32, 32, 96)   24672       concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 32, 32, 16)   4112        concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 32, 32, 256)  0           concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 32, 32, 64)   16448       concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 32, 32, 128)  110720      conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 32, 32, 32)   12832       conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 32, 32, 32)   8224        max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 32, 32, 256)  0           conv2d_12[0][0]                  \n",
            "                                                                 conv2d_14[0][0]                  \n",
            "                                                                 conv2d_16[0][0]                  \n",
            "                                                                 conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 32, 32, 96)   24672       concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 32, 32, 16)   4112        concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 32, 32, 256)  0           concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 32, 32, 64)   16448       concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 32, 32, 128)  110720      conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 32, 32, 32)   12832       conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 32, 32, 32)   8224        max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 32, 32, 256)  0           conv2d_18[0][0]                  \n",
            "                                                                 conv2d_20[0][0]                  \n",
            "                                                                 conv2d_22[0][0]                  \n",
            "                                                                 conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 32, 32, 8)    18440       concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2D)  (None, 10, 10, 8)    0           conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 800)          0           max_pooling2d_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 100)          80100       flatten[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 753,948\n",
            "Trainable params: 753,948\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wNXVRhvpsCwi"
      },
      "source": [
        "opt = keras.optimizers.Adam(learning_rate=0.0001, clipnorm=5)\n",
        "model.compile(loss=keras.losses.categorical_crossentropy, optimizer=opt, metrics=[\"accuracy\"])"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E6Hea7ZxrbKJ",
        "outputId": "17da5d2b-fe89-4f95-e652-89271bf35d8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "callback = EarlyStopping(monitor='val_loss', patience=20)\n",
        "history = model.fit(x_train, y_train, batch_size=128, epochs=100, verbose=1, validation_data=(x_test, y_test), callbacks=[callback])\n",
        "model.save_weights(filepath=F\"/content/gdrive/My Drive/Checkpoints/InceptionV2_ADAM_NoRegularization.h5\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "391/391 [==============================] - 28s 71ms/step - loss: 4.1524 - accuracy: 0.0738 - val_loss: 3.7964 - val_accuracy: 0.1315\n",
            "Epoch 2/100\n",
            "391/391 [==============================] - 27s 70ms/step - loss: 3.6170 - accuracy: 0.1586 - val_loss: 3.5168 - val_accuracy: 0.1794\n",
            "Epoch 3/100\n",
            "391/391 [==============================] - 27s 70ms/step - loss: 3.3861 - accuracy: 0.1988 - val_loss: 3.3257 - val_accuracy: 0.2127\n",
            "Epoch 4/100\n",
            "391/391 [==============================] - 27s 70ms/step - loss: 3.2253 - accuracy: 0.2298 - val_loss: 3.2019 - val_accuracy: 0.2329\n",
            "Epoch 5/100\n",
            "391/391 [==============================] - 27s 70ms/step - loss: 3.0972 - accuracy: 0.2531 - val_loss: 3.0985 - val_accuracy: 0.2523\n",
            "Epoch 6/100\n",
            "391/391 [==============================] - 27s 69ms/step - loss: 2.9937 - accuracy: 0.2704 - val_loss: 3.0335 - val_accuracy: 0.2635\n",
            "Epoch 7/100\n",
            "391/391 [==============================] - 27s 70ms/step - loss: 2.9090 - accuracy: 0.2885 - val_loss: 2.9646 - val_accuracy: 0.2801\n",
            "Epoch 8/100\n",
            "391/391 [==============================] - 27s 70ms/step - loss: 2.8378 - accuracy: 0.3032 - val_loss: 2.9158 - val_accuracy: 0.2879\n",
            "Epoch 9/100\n",
            "391/391 [==============================] - 27s 70ms/step - loss: 2.7678 - accuracy: 0.3187 - val_loss: 2.8685 - val_accuracy: 0.2989\n",
            "Epoch 10/100\n",
            "391/391 [==============================] - 27s 70ms/step - loss: 2.7048 - accuracy: 0.3309 - val_loss: 2.8141 - val_accuracy: 0.3095\n",
            "Epoch 11/100\n",
            "391/391 [==============================] - 27s 70ms/step - loss: 2.6440 - accuracy: 0.3429 - val_loss: 2.7814 - val_accuracy: 0.3195\n",
            "Epoch 12/100\n",
            "391/391 [==============================] - 27s 69ms/step - loss: 2.5844 - accuracy: 0.3560 - val_loss: 2.7424 - val_accuracy: 0.3243\n",
            "Epoch 13/100\n",
            "391/391 [==============================] - 27s 70ms/step - loss: 2.5258 - accuracy: 0.3677 - val_loss: 2.6958 - val_accuracy: 0.3348\n",
            "Epoch 14/100\n",
            "391/391 [==============================] - 27s 70ms/step - loss: 2.4661 - accuracy: 0.3816 - val_loss: 2.6606 - val_accuracy: 0.3428\n",
            "Epoch 15/100\n",
            "391/391 [==============================] - 27s 70ms/step - loss: 2.4047 - accuracy: 0.3946 - val_loss: 2.6049 - val_accuracy: 0.3490\n",
            "Epoch 16/100\n",
            "391/391 [==============================] - 27s 70ms/step - loss: 2.3545 - accuracy: 0.4029 - val_loss: 2.5574 - val_accuracy: 0.3632\n",
            "Epoch 17/100\n",
            "391/391 [==============================] - 27s 70ms/step - loss: 2.2992 - accuracy: 0.4143 - val_loss: 2.5287 - val_accuracy: 0.3704\n",
            "Epoch 18/100\n",
            "391/391 [==============================] - 27s 70ms/step - loss: 2.2508 - accuracy: 0.4251 - val_loss: 2.5107 - val_accuracy: 0.3719\n",
            "Epoch 19/100\n",
            "391/391 [==============================] - 27s 70ms/step - loss: 2.2113 - accuracy: 0.4348 - val_loss: 2.5044 - val_accuracy: 0.3764\n",
            "Epoch 20/100\n",
            "391/391 [==============================] - 27s 70ms/step - loss: 2.1733 - accuracy: 0.4411 - val_loss: 2.4571 - val_accuracy: 0.3830\n",
            "Epoch 21/100\n",
            "391/391 [==============================] - 27s 70ms/step - loss: 2.1310 - accuracy: 0.4530 - val_loss: 2.4491 - val_accuracy: 0.3844\n",
            "Epoch 22/100\n",
            "391/391 [==============================] - 27s 70ms/step - loss: 2.1027 - accuracy: 0.4582 - val_loss: 2.4092 - val_accuracy: 0.3920\n",
            "Epoch 23/100\n",
            "391/391 [==============================] - 27s 70ms/step - loss: 2.0604 - accuracy: 0.4670 - val_loss: 2.4234 - val_accuracy: 0.3922\n",
            "Epoch 24/100\n",
            "391/391 [==============================] - 27s 70ms/step - loss: 2.0303 - accuracy: 0.4729 - val_loss: 2.4182 - val_accuracy: 0.3932\n",
            "Epoch 25/100\n",
            "391/391 [==============================] - 27s 70ms/step - loss: 2.0032 - accuracy: 0.4803 - val_loss: 2.4071 - val_accuracy: 0.3897\n",
            "Epoch 26/100\n",
            "391/391 [==============================] - 27s 70ms/step - loss: 1.9665 - accuracy: 0.4891 - val_loss: 2.3673 - val_accuracy: 0.4002\n",
            "Epoch 27/100\n",
            "391/391 [==============================] - 27s 70ms/step - loss: 1.9379 - accuracy: 0.4961 - val_loss: 2.3717 - val_accuracy: 0.4012\n",
            "Epoch 28/100\n",
            "391/391 [==============================] - 27s 70ms/step - loss: 1.9122 - accuracy: 0.5022 - val_loss: 2.3789 - val_accuracy: 0.4007\n",
            "Epoch 29/100\n",
            "391/391 [==============================] - 27s 70ms/step - loss: 1.8842 - accuracy: 0.5058 - val_loss: 2.3633 - val_accuracy: 0.4058\n",
            "Epoch 30/100\n",
            "391/391 [==============================] - 27s 70ms/step - loss: 1.8562 - accuracy: 0.5132 - val_loss: 2.3676 - val_accuracy: 0.4025\n",
            "Epoch 31/100\n",
            "391/391 [==============================] - 28s 70ms/step - loss: 1.8319 - accuracy: 0.5195 - val_loss: 2.3606 - val_accuracy: 0.4073\n",
            "Epoch 32/100\n",
            "391/391 [==============================] - 27s 70ms/step - loss: 1.8032 - accuracy: 0.5263 - val_loss: 2.3593 - val_accuracy: 0.4077\n",
            "Epoch 33/100\n",
            "391/391 [==============================] - 27s 70ms/step - loss: 1.7758 - accuracy: 0.5333 - val_loss: 2.3549 - val_accuracy: 0.4069\n",
            "Epoch 34/100\n",
            "391/391 [==============================] - 27s 70ms/step - loss: 1.7464 - accuracy: 0.5404 - val_loss: 2.3639 - val_accuracy: 0.4069\n",
            "Epoch 35/100\n",
            "391/391 [==============================] - 27s 70ms/step - loss: 1.7191 - accuracy: 0.5458 - val_loss: 2.3657 - val_accuracy: 0.4063\n",
            "Epoch 36/100\n",
            "391/391 [==============================] - 27s 70ms/step - loss: 1.6934 - accuracy: 0.5532 - val_loss: 2.3736 - val_accuracy: 0.4108\n",
            "Epoch 37/100\n",
            "391/391 [==============================] - 27s 70ms/step - loss: 1.6656 - accuracy: 0.5581 - val_loss: 2.3663 - val_accuracy: 0.4127\n",
            "Epoch 38/100\n",
            "391/391 [==============================] - 27s 70ms/step - loss: 1.6371 - accuracy: 0.5659 - val_loss: 2.3934 - val_accuracy: 0.4123\n",
            "Epoch 39/100\n",
            "391/391 [==============================] - 27s 70ms/step - loss: 1.6135 - accuracy: 0.5711 - val_loss: 2.4101 - val_accuracy: 0.4109\n",
            "Epoch 40/100\n",
            "391/391 [==============================] - 27s 70ms/step - loss: 1.5863 - accuracy: 0.5771 - val_loss: 2.4097 - val_accuracy: 0.4124\n",
            "Epoch 41/100\n",
            "391/391 [==============================] - 27s 70ms/step - loss: 1.5563 - accuracy: 0.5864 - val_loss: 2.4402 - val_accuracy: 0.4067\n",
            "Epoch 42/100\n",
            "391/391 [==============================] - 27s 70ms/step - loss: 1.5284 - accuracy: 0.5920 - val_loss: 2.4242 - val_accuracy: 0.4162\n",
            "Epoch 43/100\n",
            "391/391 [==============================] - 27s 70ms/step - loss: 1.5019 - accuracy: 0.5997 - val_loss: 2.4299 - val_accuracy: 0.4178\n",
            "Epoch 44/100\n",
            "391/391 [==============================] - 27s 70ms/step - loss: 1.4744 - accuracy: 0.6054 - val_loss: 2.4527 - val_accuracy: 0.4137\n",
            "Epoch 45/100\n",
            "391/391 [==============================] - 27s 70ms/step - loss: 1.4469 - accuracy: 0.6131 - val_loss: 2.4881 - val_accuracy: 0.4064\n",
            "Epoch 46/100\n",
            "391/391 [==============================] - 27s 69ms/step - loss: 1.4154 - accuracy: 0.6216 - val_loss: 2.5000 - val_accuracy: 0.4070\n",
            "Epoch 47/100\n",
            "391/391 [==============================] - 27s 69ms/step - loss: 1.3879 - accuracy: 0.6271 - val_loss: 2.4959 - val_accuracy: 0.4078\n",
            "Epoch 48/100\n",
            "391/391 [==============================] - 27s 69ms/step - loss: 1.3587 - accuracy: 0.6360 - val_loss: 2.5662 - val_accuracy: 0.4025\n",
            "Epoch 49/100\n",
            "391/391 [==============================] - 27s 69ms/step - loss: 1.3276 - accuracy: 0.6422 - val_loss: 2.5463 - val_accuracy: 0.4086\n",
            "Epoch 50/100\n",
            "391/391 [==============================] - 27s 70ms/step - loss: 1.2963 - accuracy: 0.6524 - val_loss: 2.5827 - val_accuracy: 0.4101\n",
            "Epoch 51/100\n",
            "391/391 [==============================] - 27s 69ms/step - loss: 1.2682 - accuracy: 0.6612 - val_loss: 2.6076 - val_accuracy: 0.4086\n",
            "Epoch 52/100\n",
            "391/391 [==============================] - 27s 70ms/step - loss: 1.2399 - accuracy: 0.6655 - val_loss: 2.6581 - val_accuracy: 0.4033\n",
            "Epoch 53/100\n",
            "391/391 [==============================] - 27s 69ms/step - loss: 1.2086 - accuracy: 0.6749 - val_loss: 2.6627 - val_accuracy: 0.4035\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZuWXGeW-nqY",
        "outputId": "5689fcd6-de73-4954-e3bf-c9942eabd210",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "history_dict = history.history\n",
        "print(history_dict.keys())\n",
        "loss_values = history_dict['loss']\n",
        "val_loss_values = history_dict['val_loss']\n",
        "\n",
        "epochs = range(1, len(history_dict['accuracy']) + 1)\n",
        "\n",
        "plt.plot(epochs, loss_values, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss_values, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AfO0lHJIE0Gy",
        "outputId": "71dfe6f0-ff50-4a1c-d716-19f6ebdb2a32",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "y_pred = model.predict(x_test).argmax(-1)\n",
        "import sklearn.metrics as metrics\n",
        "print(metrics.classification_report(y_test.argmax(axis=1), y_pred))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.70      0.67      0.68       100\n",
            "           1       0.40      0.55      0.46       100\n",
            "           2       0.20      0.23      0.21       100\n",
            "           3       0.20      0.22      0.21       100\n",
            "           4       0.24      0.32      0.27       100\n",
            "           5       0.37      0.45      0.41       100\n",
            "           6       0.47      0.48      0.48       100\n",
            "           7       0.42      0.47      0.44       100\n",
            "           8       0.68      0.50      0.58       100\n",
            "           9       0.49      0.56      0.52       100\n",
            "          10       0.34      0.42      0.38       100\n",
            "          11       0.22      0.27      0.24       100\n",
            "          12       0.29      0.45      0.35       100\n",
            "          13       0.33      0.37      0.35       100\n",
            "          14       0.35      0.27      0.30       100\n",
            "          15       0.26      0.36      0.31       100\n",
            "          16       0.37      0.52      0.43       100\n",
            "          17       0.61      0.59      0.60       100\n",
            "          18       0.28      0.13      0.18       100\n",
            "          19       0.33      0.27      0.30       100\n",
            "          20       0.63      0.69      0.66       100\n",
            "          21       0.48      0.65      0.55       100\n",
            "          22       0.36      0.37      0.37       100\n",
            "          23       0.67      0.48      0.56       100\n",
            "          24       0.63      0.46      0.53       100\n",
            "          25       0.31      0.30      0.30       100\n",
            "          26       0.47      0.27      0.34       100\n",
            "          27       0.27      0.28      0.28       100\n",
            "          28       0.65      0.68      0.67       100\n",
            "          29       0.49      0.35      0.41       100\n",
            "          30       0.35      0.32      0.34       100\n",
            "          31       0.36      0.34      0.35       100\n",
            "          32       0.32      0.24      0.28       100\n",
            "          33       0.43      0.52      0.47       100\n",
            "          34       0.32      0.44      0.37       100\n",
            "          35       0.28      0.13      0.18       100\n",
            "          36       0.35      0.45      0.39       100\n",
            "          37       0.35      0.47      0.40       100\n",
            "          38       0.28      0.25      0.26       100\n",
            "          39       0.44      0.33      0.38       100\n",
            "          40       0.37      0.33      0.35       100\n",
            "          41       0.61      0.57      0.59       100\n",
            "          42       0.39      0.37      0.38       100\n",
            "          43       0.33      0.41      0.36       100\n",
            "          44       0.17      0.12      0.14       100\n",
            "          45       0.27      0.25      0.26       100\n",
            "          46       0.27      0.23      0.25       100\n",
            "          47       0.46      0.61      0.53       100\n",
            "          48       0.67      0.70      0.69       100\n",
            "          49       0.70      0.47      0.56       100\n",
            "          50       0.21      0.14      0.17       100\n",
            "          51       0.28      0.22      0.25       100\n",
            "          52       0.51      0.50      0.50       100\n",
            "          53       0.61      0.72      0.66       100\n",
            "          54       0.45      0.45      0.45       100\n",
            "          55       0.07      0.05      0.06       100\n",
            "          56       0.57      0.52      0.54       100\n",
            "          57       0.46      0.46      0.46       100\n",
            "          58       0.41      0.48      0.44       100\n",
            "          59       0.41      0.31      0.35       100\n",
            "          60       0.67      0.77      0.72       100\n",
            "          61       0.60      0.50      0.54       100\n",
            "          62       0.49      0.52      0.50       100\n",
            "          63       0.43      0.30      0.35       100\n",
            "          64       0.19      0.21      0.20       100\n",
            "          65       0.20      0.20      0.20       100\n",
            "          66       0.30      0.24      0.27       100\n",
            "          67       0.37      0.26      0.30       100\n",
            "          68       0.71      0.75      0.73       100\n",
            "          69       0.43      0.67      0.53       100\n",
            "          70       0.39      0.46      0.42       100\n",
            "          71       0.58      0.64      0.61       100\n",
            "          72       0.18      0.13      0.15       100\n",
            "          73       0.39      0.23      0.29       100\n",
            "          74       0.20      0.17      0.19       100\n",
            "          75       0.56      0.57      0.57       100\n",
            "          76       0.58      0.66      0.62       100\n",
            "          77       0.32      0.23      0.27       100\n",
            "          78       0.20      0.12      0.15       100\n",
            "          79       0.43      0.50      0.46       100\n",
            "          80       0.15      0.15      0.15       100\n",
            "          81       0.41      0.57      0.47       100\n",
            "          82       0.70      0.63      0.66       100\n",
            "          83       0.35      0.25      0.29       100\n",
            "          84       0.29      0.33      0.31       100\n",
            "          85       0.53      0.46      0.49       100\n",
            "          86       0.48      0.40      0.44       100\n",
            "          87       0.50      0.56      0.53       100\n",
            "          88       0.38      0.40      0.39       100\n",
            "          89       0.39      0.50      0.44       100\n",
            "          90       0.34      0.30      0.32       100\n",
            "          91       0.38      0.52      0.44       100\n",
            "          92       0.36      0.38      0.37       100\n",
            "          93       0.30      0.21      0.25       100\n",
            "          94       0.71      0.74      0.73       100\n",
            "          95       0.35      0.46      0.40       100\n",
            "          96       0.45      0.36      0.40       100\n",
            "          97       0.28      0.40      0.33       100\n",
            "          98       0.22      0.25      0.23       100\n",
            "          99       0.34      0.32      0.33       100\n",
            "\n",
            "    accuracy                           0.40     10000\n",
            "   macro avg       0.40      0.40      0.40     10000\n",
            "weighted avg       0.40      0.40      0.40     10000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_Ua68UfyP4j"
      },
      "source": [
        "# TESTS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T4Smel9NqS1r"
      },
      "source": [
        "# model.load_weights(filepath=F\"/content/gdrive/My Drive/Checkpoints/InceptionV2_ADAM_NoRegularization.h5\")\n",
        "\n",
        "model.load_weights(\"InceptionV2_ADAM_NoRegularization.h5\")"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0XDBMyDq0d3",
        "outputId": "fd0b1074-196a-4c28-973d-22e5c1ebf057",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "result = model.evaluate(batch_size=128, x=x_test, y=y_test)\n",
        "dict(zip(model.metrics_names,result))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "79/79 [==============================] - 2s 23ms/step - loss: 2.6627 - accuracy: 0.4035\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 0.4034999907016754, 'loss': 2.6627461910247803}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_dkY0ZB477h"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}