{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "InceptionV2_SGD_BatchNormalization.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qe3UvwFPYKMT"
      },
      "source": [
        "## Load Data Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Su96RREPI5li",
        "outputId": "577cefcf-0823-40eb-8247-f76dd00db8a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ixBthpNWrKzY"
      },
      "source": [
        "from keras.datasets import cifar100\n",
        "from keras.utils import to_categorical\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "from keras import backend as K"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d14LEXbNqu68",
        "outputId": "2cf05bfb-4d5b-4279-c246-3a395d9b23c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "(x_train, y_train_), (x_test, y_test_) = cifar100.load_data()\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
            "169009152/169001437 [==============================] - 6s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p4lTzEl8djyJ"
      },
      "source": [
        "x_train = x_train.astype('float32') / 255\n",
        "x_test = x_test.astype('float32') / 255"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6h_PwVSJrWjf"
      },
      "source": [
        "y_train = to_categorical(y_train_)\n",
        "y_test = to_categorical(y_test_)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fsSOLpMSYEKL"
      },
      "source": [
        "## Inception V2 model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DlX5MwqCoSEF"
      },
      "source": [
        "import keras\n",
        "import tensorflow as tf\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense, Activation, Dropout, Flatten, Reshape\n",
        "from keras.layers import Conv2D, Input\n",
        "from keras.layers import MaxPooling2D, BatchNormalization\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.layers.merge import concatenate\n",
        "import os"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RfDkIclipUCR"
      },
      "source": [
        "input_shape = (32, 32, 3)\n",
        "input = Input(shape=input_shape)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t1Cv1ygQ7Cwj"
      },
      "source": [
        "layer1_1 = Conv2D(64, (1, 1), activation='elu', padding='same')(input)\n",
        "layer1_2 = Conv2D(96, (1, 1), activation='elu', padding='same')(input)\n",
        "layer1_2 = Conv2D(128, (3, 3), activation='elu', padding='same')(layer1_2)\n",
        "layer1_3 = Conv2D(16, (1, 1), activation='elu', padding='same')(input)\n",
        "layer1_3 = Conv2D(32, (5, 5), activation='elu', padding='same')(layer1_3)\n",
        "layer1_4 = MaxPooling2D(pool_size=(3, 3), strides=(1, 1), padding='same', data_format='channels_last')(input)\n",
        "layer1_4 = Conv2D(32, (1, 1), activation='elu', padding='same')(layer1_4)\n",
        " \n",
        "concat = concatenate([layer1_1, layer1_2, layer1_3, layer1_4])\n",
        "concat = BatchNormalization()(concat)\n",
        "concat = Activation('elu')(concat)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZgqX4ij5wn7J"
      },
      "source": [
        "layer2_1 = Conv2D(64, (1, 1), activation='elu', padding='same')(concat)\n",
        "layer2_2 = Conv2D(96, (1, 1), activation='elu', padding='same')(concat)\n",
        "layer2_2 = Conv2D(128, (3, 3), activation='elu', padding='same')(layer2_2)\n",
        "layer2_3 = Conv2D(16, (1, 1), activation='elu', padding='same')(concat)\n",
        "layer2_3 = Conv2D(32, (5, 5), activation='elu', padding='same')(layer2_3)\n",
        "layer2_4 = MaxPooling2D(pool_size=(3, 3), strides=(1, 1), padding='same', data_format='channels_last')(concat)\n",
        "layer2_4 = Conv2D(32, (1, 1), activation='elu', padding='same')(layer2_4)\n",
        "\n",
        "concat2 = concatenate([layer2_1, layer2_2, layer2_3, layer2_4])\n",
        "concat2 = BatchNormalization()(concat2)\n",
        "concat2 = Activation('elu')(concat2)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4RzN660c7naC"
      },
      "source": [
        "# layer3_1 = Conv2D(64, (1, 1), activation='elu', padding='same')(concat2)\n",
        "# layer3_2 = Conv2D(96, (1, 1), activation='elu', padding='same')(concat2)\n",
        "# layer3_2 = Conv2D(128, (3, 3), activation='elu', padding='same')(layer3_2)\n",
        "# layer3_3 = Conv2D(16, (1, 1), activation='elu', padding='same')(concat2)\n",
        "# layer3_3 = Conv2D(32, (5, 5), activation='elu', padding='same')(layer3_3)\n",
        "# layer3_4 = MaxPooling2D(pool_size=(3, 3), strides=(1, 1), padding='same', data_format='channels_last')(concat2)\n",
        "# layer3_4 = Conv2D(32, (1, 1), activation='elu', padding='same')(layer3_4)\n",
        "\n",
        "# concat3 = concatenate([layer3_1, layer3_2, layer3_3, layer3_4])\n",
        "# concat3 = BatchNormalization()(concat3)\n",
        "# concat3 = Activation('elu')(concat3)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BqQohLdvpaGV",
        "outputId": "59d91f9e-1037-47f1-8484-97b1ae2dd4bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# layer4_1 = Conv2D(64, (1, 1), activation='elu', padding='same')(concat3)\n",
        "# layer4_2 = Conv2D(96, (1, 1), activation='elu', padding='same')(concat3)\n",
        "# layer4_2 = Conv2D(128, (3, 3), activation='elu', padding='same')(layer4_2)\n",
        "# layer4_3 = Conv2D(16, (1, 1), activation='elu', padding='same')(concat3)\n",
        "# layer4_3 = Conv2D(32, (5, 5), activation='elu', padding='same')(layer4_3)\n",
        "# layer4_4 = MaxPooling2D(pool_size=(3, 3), strides=(1, 1), padding='same', data_format='channels_last')(concat3)\n",
        "# layer4_4 = Conv2D(32, (1, 1), activation='elu', padding='same')(layer4_4)\n",
        "\n",
        "# concat4 = concatenate([layer4_1, layer4_2, layer4_3, layer4_4])\n",
        "# concat4 = BatchNormalization()(concat4)\n",
        "# concat4 = Activation('elu')(concat4)\n",
        "\n",
        "output = Conv2D(8, (3, 3), activation=tf.keras.layers.LeakyReLU(alpha=0.3), padding='same')(concat2)\n",
        "output = MaxPooling2D(pool_size=(3, 3))(output)\n",
        "output = Flatten()(output)                 \n",
        "output = Dense(100, activation='softmax')(output) \n",
        "\n",
        "model = Model(inputs=input, outputs=output) \n",
        "model.summary()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 32, 32, 96)   384         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 32, 32, 16)   64          input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 32, 32, 3)    0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 32, 32, 64)   256         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 32, 32, 128)  110720      conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 32, 32, 32)   12832       conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 32, 32, 32)   128         max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 32, 32, 256)  0           conv2d[0][0]                     \n",
            "                                                                 conv2d_2[0][0]                   \n",
            "                                                                 conv2d_4[0][0]                   \n",
            "                                                                 conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 32, 32, 256)  1024        concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 32, 32, 256)  0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 32, 32, 96)   24672       activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 32, 32, 16)   4112        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 32, 32, 256)  0           activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 32, 32, 64)   16448       activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 32, 32, 128)  110720      conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 32, 32, 32)   12832       conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 32, 32, 32)   8224        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 32, 32, 256)  0           conv2d_6[0][0]                   \n",
            "                                                                 conv2d_8[0][0]                   \n",
            "                                                                 conv2d_10[0][0]                  \n",
            "                                                                 conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 32, 32, 256)  1024        concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 32, 32, 256)  0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 32, 32, 8)    18440       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 10, 10, 8)    0           conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 800)          0           max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 100)          80100       flatten[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 401,980\n",
            "Trainable params: 400,956\n",
            "Non-trainable params: 1,024\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wNXVRhvpsCwi",
        "outputId": "51dc9381-2dfe-4f75-8b30-24f2e90fbd30",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "opt = keras.optimizers.SGD(learning_rate=0.01, clipnorm=5)\n",
        "model.compile(loss=keras.losses.categorical_crossentropy, optimizer=opt, metrics=[\"accuracy\"])\n",
        "callback = EarlyStopping(monitor='val_loss', patience=20)\n",
        "history = model.fit(x_train, y_train, batch_size=128, epochs=200, verbose=1, validation_data=(x_test, y_test), callbacks=[callback])\n",
        "model.save_weights(filepath=F\"/content/gdrive/My Drive/Checkpoints/InceptionV2_SGD_BatchNormalization.h5\")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "391/391 [==============================] - 16s 40ms/step - loss: 4.3246 - accuracy: 0.0542 - val_loss: 4.2056 - val_accuracy: 0.0594\n",
            "Epoch 2/200\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 3.7688 - accuracy: 0.1315 - val_loss: 3.7049 - val_accuracy: 0.1376\n",
            "Epoch 3/200\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 3.4595 - accuracy: 0.1824 - val_loss: 3.6072 - val_accuracy: 0.1626\n",
            "Epoch 4/200\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 3.2461 - accuracy: 0.2208 - val_loss: 3.2579 - val_accuracy: 0.2211\n",
            "Epoch 5/200\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 3.1020 - accuracy: 0.2477 - val_loss: 3.2469 - val_accuracy: 0.2223\n",
            "Epoch 6/200\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 2.9770 - accuracy: 0.2726 - val_loss: 3.1608 - val_accuracy: 0.2479\n",
            "Epoch 7/200\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 2.8786 - accuracy: 0.2925 - val_loss: 3.1361 - val_accuracy: 0.2556\n",
            "Epoch 8/200\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 2.7908 - accuracy: 0.3109 - val_loss: 3.0643 - val_accuracy: 0.2617\n",
            "Epoch 9/200\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 2.7082 - accuracy: 0.3279 - val_loss: 3.3143 - val_accuracy: 0.2388\n",
            "Epoch 10/200\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 2.6360 - accuracy: 0.3413 - val_loss: 2.8964 - val_accuracy: 0.2894\n",
            "Epoch 11/200\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 2.5734 - accuracy: 0.3565 - val_loss: 2.8648 - val_accuracy: 0.3015\n",
            "Epoch 12/200\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 2.5161 - accuracy: 0.3679 - val_loss: 2.7916 - val_accuracy: 0.3129\n",
            "Epoch 13/200\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 2.4631 - accuracy: 0.3775 - val_loss: 2.7354 - val_accuracy: 0.3225\n",
            "Epoch 14/200\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 2.4116 - accuracy: 0.3890 - val_loss: 3.4299 - val_accuracy: 0.2316\n",
            "Epoch 15/200\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 2.3683 - accuracy: 0.3993 - val_loss: 3.0344 - val_accuracy: 0.2844\n",
            "Epoch 16/200\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 2.3249 - accuracy: 0.4060 - val_loss: 2.6987 - val_accuracy: 0.3284\n",
            "Epoch 17/200\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 2.2814 - accuracy: 0.4169 - val_loss: 2.7708 - val_accuracy: 0.3254\n",
            "Epoch 18/200\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 2.2437 - accuracy: 0.4247 - val_loss: 2.6983 - val_accuracy: 0.3298\n",
            "Epoch 19/200\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 2.2056 - accuracy: 0.4353 - val_loss: 2.7102 - val_accuracy: 0.3346\n",
            "Epoch 20/200\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 2.1691 - accuracy: 0.4425 - val_loss: 2.8243 - val_accuracy: 0.3170\n",
            "Epoch 21/200\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 2.1376 - accuracy: 0.4502 - val_loss: 2.5781 - val_accuracy: 0.3589\n",
            "Epoch 22/200\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 2.1010 - accuracy: 0.4592 - val_loss: 2.7400 - val_accuracy: 0.3266\n",
            "Epoch 23/200\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 2.0707 - accuracy: 0.4648 - val_loss: 2.8527 - val_accuracy: 0.3124\n",
            "Epoch 24/200\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 2.0401 - accuracy: 0.4725 - val_loss: 2.6150 - val_accuracy: 0.3565\n",
            "Epoch 25/200\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 2.0103 - accuracy: 0.4794 - val_loss: 2.6738 - val_accuracy: 0.3453\n",
            "Epoch 26/200\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 1.9825 - accuracy: 0.4837 - val_loss: 2.7622 - val_accuracy: 0.3437\n",
            "Epoch 27/200\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 1.9502 - accuracy: 0.4929 - val_loss: 2.6857 - val_accuracy: 0.3517\n",
            "Epoch 28/200\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 1.9247 - accuracy: 0.4997 - val_loss: 2.6116 - val_accuracy: 0.3628\n",
            "Epoch 29/200\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 1.8938 - accuracy: 0.5045 - val_loss: 2.6842 - val_accuracy: 0.3550\n",
            "Epoch 30/200\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 1.8684 - accuracy: 0.5123 - val_loss: 2.6779 - val_accuracy: 0.3553\n",
            "Epoch 31/200\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 1.8463 - accuracy: 0.5164 - val_loss: 2.6135 - val_accuracy: 0.3663\n",
            "Epoch 32/200\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 1.8192 - accuracy: 0.5230 - val_loss: 2.5845 - val_accuracy: 0.3705\n",
            "Epoch 33/200\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 1.7941 - accuracy: 0.5277 - val_loss: 2.6037 - val_accuracy: 0.3670\n",
            "Epoch 34/200\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 1.7679 - accuracy: 0.5356 - val_loss: 2.6261 - val_accuracy: 0.3603\n",
            "Epoch 35/200\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 1.7459 - accuracy: 0.5408 - val_loss: 2.6315 - val_accuracy: 0.3670\n",
            "Epoch 36/200\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 1.7210 - accuracy: 0.5457 - val_loss: 2.5518 - val_accuracy: 0.3811\n",
            "Epoch 37/200\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 1.7003 - accuracy: 0.5517 - val_loss: 2.6064 - val_accuracy: 0.3776\n",
            "Epoch 38/200\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 1.6735 - accuracy: 0.5578 - val_loss: 2.6456 - val_accuracy: 0.3751\n",
            "Epoch 39/200\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 1.6501 - accuracy: 0.5647 - val_loss: 2.6218 - val_accuracy: 0.3758\n",
            "Epoch 40/200\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 1.6283 - accuracy: 0.5684 - val_loss: 2.6448 - val_accuracy: 0.3700\n",
            "Epoch 41/200\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 1.6068 - accuracy: 0.5715 - val_loss: 2.7075 - val_accuracy: 0.3629\n",
            "Epoch 42/200\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 1.5808 - accuracy: 0.5809 - val_loss: 2.7542 - val_accuracy: 0.3535\n",
            "Epoch 43/200\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 1.5609 - accuracy: 0.5844 - val_loss: 2.7263 - val_accuracy: 0.3676\n",
            "Epoch 44/200\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 1.5405 - accuracy: 0.5899 - val_loss: 2.6834 - val_accuracy: 0.3683\n",
            "Epoch 45/200\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 1.5166 - accuracy: 0.5944 - val_loss: 2.6622 - val_accuracy: 0.3763\n",
            "Epoch 46/200\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 1.4930 - accuracy: 0.5994 - val_loss: 2.7653 - val_accuracy: 0.3600\n",
            "Epoch 47/200\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 1.4741 - accuracy: 0.6055 - val_loss: 2.6768 - val_accuracy: 0.3788\n",
            "Epoch 48/200\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 1.4498 - accuracy: 0.6116 - val_loss: 2.7823 - val_accuracy: 0.3693\n",
            "Epoch 49/200\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 1.4271 - accuracy: 0.6159 - val_loss: 2.8006 - val_accuracy: 0.3669\n",
            "Epoch 50/200\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 1.4055 - accuracy: 0.6228 - val_loss: 2.7703 - val_accuracy: 0.3761\n",
            "Epoch 51/200\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 1.3866 - accuracy: 0.6270 - val_loss: 2.7612 - val_accuracy: 0.3717\n",
            "Epoch 52/200\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 1.3645 - accuracy: 0.6320 - val_loss: 2.8042 - val_accuracy: 0.3660\n",
            "Epoch 53/200\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 1.3473 - accuracy: 0.6371 - val_loss: 2.8796 - val_accuracy: 0.3517\n",
            "Epoch 54/200\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 1.3219 - accuracy: 0.6421 - val_loss: 2.8917 - val_accuracy: 0.3656\n",
            "Epoch 55/200\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 1.3030 - accuracy: 0.6469 - val_loss: 2.9016 - val_accuracy: 0.3644\n",
            "Epoch 56/200\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 1.2858 - accuracy: 0.6533 - val_loss: 2.8572 - val_accuracy: 0.3667\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PK9Ww8AJYaaM"
      },
      "source": [
        "## Test Metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZuWXGeW-nqY",
        "outputId": "24448a63-9756-4971-becb-56e7c159b306",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "history_dict = history.history\n",
        "print(history_dict.keys())\n",
        "loss_values = history_dict['loss']\n",
        "val_loss_values = history_dict['val_loss']\n",
        "\n",
        "epochs = range(1, len(history_dict['accuracy']) + 1)\n",
        "\n",
        "plt.plot(epochs, loss_values, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss_values, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AfO0lHJIE0Gy",
        "outputId": "1955c782-0d0c-42ef-af39-4a4ad71fd22b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "y_pred = model.predict(x_test).argmax(-1)\n",
        "import sklearn.metrics as metrics\n",
        "print(metrics.classification_report(y_test.argmax(axis=1), y_pred))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.59      0.70      0.64       100\n",
            "           1       0.50      0.48      0.49       100\n",
            "           2       0.20      0.14      0.16       100\n",
            "           3       0.13      0.13      0.13       100\n",
            "           4       0.22      0.20      0.21       100\n",
            "           5       0.37      0.31      0.34       100\n",
            "           6       0.42      0.45      0.43       100\n",
            "           7       0.36      0.44      0.40       100\n",
            "           8       0.69      0.41      0.52       100\n",
            "           9       0.53      0.55      0.54       100\n",
            "          10       0.25      0.28      0.26       100\n",
            "          11       0.21      0.23      0.22       100\n",
            "          12       0.36      0.35      0.36       100\n",
            "          13       0.34      0.38      0.36       100\n",
            "          14       0.26      0.25      0.26       100\n",
            "          15       0.32      0.28      0.30       100\n",
            "          16       0.34      0.36      0.35       100\n",
            "          17       0.59      0.37      0.45       100\n",
            "          18       0.27      0.23      0.25       100\n",
            "          19       0.31      0.26      0.28       100\n",
            "          20       0.74      0.62      0.67       100\n",
            "          21       0.46      0.49      0.48       100\n",
            "          22       0.35      0.36      0.35       100\n",
            "          23       0.50      0.52      0.51       100\n",
            "          24       0.55      0.59      0.57       100\n",
            "          25       0.26      0.30      0.28       100\n",
            "          26       0.36      0.29      0.32       100\n",
            "          27       0.32      0.32      0.32       100\n",
            "          28       0.62      0.67      0.64       100\n",
            "          29       0.24      0.38      0.29       100\n",
            "          30       0.35      0.37      0.36       100\n",
            "          31       0.40      0.34      0.37       100\n",
            "          32       0.35      0.29      0.32       100\n",
            "          33       0.39      0.46      0.42       100\n",
            "          34       0.28      0.27      0.28       100\n",
            "          35       0.16      0.17      0.16       100\n",
            "          36       0.30      0.31      0.30       100\n",
            "          37       0.35      0.42      0.38       100\n",
            "          38       0.17      0.19      0.18       100\n",
            "          39       0.25      0.26      0.26       100\n",
            "          40       0.36      0.31      0.33       100\n",
            "          41       0.74      0.60      0.66       100\n",
            "          42       0.34      0.42      0.38       100\n",
            "          43       0.44      0.40      0.42       100\n",
            "          44       0.13      0.09      0.11       100\n",
            "          45       0.17      0.18      0.18       100\n",
            "          46       0.24      0.24      0.24       100\n",
            "          47       0.44      0.47      0.45       100\n",
            "          48       0.66      0.63      0.64       100\n",
            "          49       0.50      0.53      0.52       100\n",
            "          50       0.15      0.15      0.15       100\n",
            "          51       0.24      0.18      0.21       100\n",
            "          52       0.51      0.59      0.55       100\n",
            "          53       0.57      0.65      0.61       100\n",
            "          54       0.49      0.43      0.46       100\n",
            "          55       0.12      0.10      0.11       100\n",
            "          56       0.48      0.53      0.50       100\n",
            "          57       0.36      0.43      0.39       100\n",
            "          58       0.47      0.49      0.48       100\n",
            "          59       0.30      0.19      0.23       100\n",
            "          60       0.61      0.71      0.65       100\n",
            "          61       0.66      0.44      0.53       100\n",
            "          62       0.34      0.32      0.33       100\n",
            "          63       0.22      0.26      0.24       100\n",
            "          64       0.17      0.15      0.16       100\n",
            "          65       0.24      0.25      0.24       100\n",
            "          66       0.29      0.21      0.24       100\n",
            "          67       0.30      0.28      0.29       100\n",
            "          68       0.62      0.72      0.66       100\n",
            "          69       0.50      0.65      0.57       100\n",
            "          70       0.41      0.37      0.39       100\n",
            "          71       0.52      0.60      0.56       100\n",
            "          72       0.09      0.11      0.10       100\n",
            "          73       0.30      0.33      0.31       100\n",
            "          74       0.21      0.16      0.18       100\n",
            "          75       0.43      0.55      0.48       100\n",
            "          76       0.51      0.65      0.57       100\n",
            "          77       0.20      0.18      0.19       100\n",
            "          78       0.15      0.15      0.15       100\n",
            "          79       0.45      0.39      0.42       100\n",
            "          80       0.19      0.13      0.16       100\n",
            "          81       0.49      0.32      0.39       100\n",
            "          82       0.64      0.52      0.57       100\n",
            "          83       0.26      0.29      0.27       100\n",
            "          84       0.27      0.19      0.22       100\n",
            "          85       0.49      0.39      0.44       100\n",
            "          86       0.41      0.36      0.38       100\n",
            "          87       0.41      0.55      0.47       100\n",
            "          88       0.27      0.19      0.22       100\n",
            "          89       0.37      0.42      0.39       100\n",
            "          90       0.33      0.41      0.36       100\n",
            "          91       0.38      0.47      0.42       100\n",
            "          92       0.37      0.29      0.32       100\n",
            "          93       0.16      0.10      0.12       100\n",
            "          94       0.64      0.74      0.69       100\n",
            "          95       0.34      0.55      0.42       100\n",
            "          96       0.33      0.44      0.37       100\n",
            "          97       0.51      0.31      0.39       100\n",
            "          98       0.15      0.22      0.18       100\n",
            "          99       0.25      0.27      0.26       100\n",
            "\n",
            "    accuracy                           0.37     10000\n",
            "   macro avg       0.37      0.37      0.36     10000\n",
            "weighted avg       0.37      0.37      0.36     10000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2xfOgbT-hQ8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T4Smel9NqS1r"
      },
      "source": [
        "# model.load_weights(filepath=F\"/content/gdrive/My Drive/Checkpoints/InceptionV2_SGD_BatchNormalization.h5\")\n",
        "\n",
        "model.load_weights(\"InceptionV2_SGD_BatchNormalization.h5\")"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0XDBMyDq0d3",
        "outputId": "9968a464-1ba4-4d19-e1ee-d50e3733f225",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "result = model.evaluate(batch_size=128, x=x_test, y=y_test)\n",
        "dict(zip(model.metrics_names,result))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "79/79 [==============================] - 1s 14ms/step - loss: 2.8572 - accuracy: 0.3667\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 0.3666999936103821, 'loss': 2.8572497367858887}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1L9dur_fSvns"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}